#!/usr/bin/env python3
"""
kå€¤ã®æ¤œè¨¼å®Ÿé¨“ - k=3ã§ã®æ€§èƒ½è©•ä¾¡
è«–æ–‡: "Uplift Modeling with High Class Imbalance" (Nyberg et al., 2021)
"""

import sys
import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data.data_generator import generate_synthetic_data
from shared.imbalance_handler import UpliftUndersampler
from shared.model import train_causal_tree, estimate_cate
from evaluation.evaluation import evaluate_cate_estimation

def create_imbalanced_dataset(n_samples=3000, positive_rate=0.05, random_seed=42):
    """
    ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    
    Args:
        n_samples (int): ã‚µãƒ³ãƒ—ãƒ«æ•°
        positive_rate (float): æ­£ä¾‹ç‡
        random_seed (int): ä¹±æ•°ã‚·ãƒ¼ãƒ‰
    
    Returns:
        X, T, Y, true_cate: ç‰¹å¾´é‡ã€å‡¦ç½®å¤‰æ•°ã€ç›®çš„å¤‰æ•°ã€çœŸã®CATE
    """
    np.random.seed(random_seed)
    
    # ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ5æ¬¡å…ƒï¼‰
    X = np.random.randn(n_samples, 5)
    
    # å‡¦ç½®å¤‰æ•°ï¼ˆãƒãƒ©ãƒ³ã‚¹å–ã‚ŒãŸå‰²ã‚Šå½“ã¦ï¼‰
    T = np.random.binomial(1, 0.5, n_samples)
    
    # çœŸã®CATEåŠ¹æœï¼ˆç‰¹å¾´é‡ã«ä¾å­˜ï¼‰
    true_cate = 0.02 + 0.01 * X[:, 0] + 0.005 * X[:, 1]  # å°ã•ãªåŠ¹æœ
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç¢ºç‡ï¼ˆä½ã„å¤‰æ›ç‡ï¼‰
    base_prob = positive_rate
    
    # å®Ÿéš›ã®å¤‰æ›ç¢ºç‡ï¼ˆå‡¦ç½®åŠ¹æœã‚’å«ã‚€ï¼‰
    prob_control = np.clip(base_prob + 0.01 * X[:, 0], 0, 1)
    prob_treatment = np.clip(prob_control + true_cate, 0, 1)
    
    # ç›®çš„å¤‰æ•°ç”Ÿæˆ
    Y = np.zeros(n_samples)
    control_mask = T == 0
    treatment_mask = T == 1
    
    Y[control_mask] = np.random.binomial(1, prob_control[control_mask])
    Y[treatment_mask] = np.random.binomial(1, prob_treatment[treatment_mask])
    
    # DataFrameã«å¤‰æ›
    X_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
    
    return X_df, T, Y, true_cate

def run_k_value_experiment(k_values=[1.5, 2.0, 3.0, 4.0, 5.0], n_samples=3000, positive_rate=0.05):
    """
    ç•°ãªã‚‹kå€¤ã§ã®æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“
    
    Args:
        k_values (list): æ¤œè¨¼ã™ã‚‹kå€¤ã®ãƒªã‚¹ãƒˆ
        n_samples (int): ã‚µãƒ³ãƒ—ãƒ«æ•°
        positive_rate (float): æ­£ä¾‹ç‡
    """
    print("=" * 70)
    print("Kå€¤æ¤œè¨¼å®Ÿé¨“ - ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åŠ¹æœã®æ¯”è¼ƒ")
    print("=" * 70)
    print(f"å®Ÿé¨“è¨­å®š:")
    print(f"- ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_samples}")
    print(f"- ç›®æ¨™æ­£ä¾‹ç‡: {positive_rate:.3f}")
    print(f"- æ¤œè¨¼ã™ã‚‹kå€¤: {k_values}")
    print()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    print("Step 1: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­...")
    X, T, Y, true_cate = create_imbalanced_dataset(
        n_samples=n_samples, 
        positive_rate=positive_rate, 
        random_seed=42
    )
    
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±:")
    print(f"- ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
    print(f"- å®Ÿéš›ã®æ­£ä¾‹ç‡: {np.mean(Y):.4f}")
    print(f"- å‡¦ç½®ç¾¤æ­£ä¾‹ç‡: {np.mean(Y[T == 1]):.4f}")
    print(f"- å¯¾ç…§ç¾¤æ­£ä¾‹ç‡: {np.mean(Y[T == 0]):.4f}")
    print()
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X_train, X_test, T_train, T_test, Y_train, Y_test, true_cate_train, true_cate_test = train_test_split(
        X, T, Y, true_cate, test_size=0.3, random_state=42, stratify=T
    )
    
    print(f"ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
    print(f"- è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)} ã‚µãƒ³ãƒ—ãƒ«")
    print(f"- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)} ã‚µãƒ³ãƒ—ãƒ«")
    print()
    
    results = []
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãªã—ï¼‰
    print("Step 2: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿé¨“ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãªã—ï¼‰")
    print("-" * 50)
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    baseline_model = train_causal_tree(
        X_train.values, T_train, Y_train,
        min_samples_leaf=20, max_depth=4, random_state=42
    )
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³äºˆæ¸¬
    baseline_pred = estimate_cate(baseline_model, X_test.values)
    baseline_eval = evaluate_cate_estimation(true_cate_test, baseline_pred)
    
    results.append({
        'k_value': 'Baseline',
        'samples_after_undersampling': len(X_train),
        'positive_rate_after': np.mean(Y_train),
        'rmse': baseline_eval['rmse'],
        'bias': baseline_eval['bias'],
        'mae': baseline_eval['mae']
    })
    
    print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœ:")
    print(f"- RMSE: {baseline_eval['rmse']:.4f}")
    print(f"- Bias: {baseline_eval['bias']:.4f}")
    print(f"- MAE: {baseline_eval['mae']:.4f}")
    print()
    
    # å„kå€¤ã§ã®å®Ÿé¨“
    for k in k_values:
        print(f"Step 3: k={k} ã§ã®ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿé¨“")
        print("-" * 50)
        
        try:
            # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œ
            undersampler = UpliftUndersampler(k=k, random_state=42)
            X_train_resampled, T_train_resampled, Y_train_resampled = undersampler.fit_resample(
                X_train, T_train, Y_train
            )
            
            print(f"ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµæœ:")
            print(f"- å…ƒã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_train)} â†’ æ–°ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_train_resampled)}")
            print(f"- å…ƒæ­£ä¾‹ç‡: {np.mean(Y_train):.4f} â†’ æ–°æ­£ä¾‹ç‡: {np.mean(Y_train_resampled):.4f}")
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            model = train_causal_tree(
                X_train_resampled.values, T_train_resampled, Y_train_resampled,
                min_samples_leaf=20, max_depth=4, random_state=42
            )
            
            # äºˆæ¸¬ã¨è£œæ­£
            pred_cate = estimate_cate(model, X_test.values)
            pred_cate_corrected = undersampler.correct_predictions(pred_cate)
            
            # è©•ä¾¡
            eval_results = evaluate_cate_estimation(true_cate_test, pred_cate_corrected)
            
            results.append({
                'k_value': k,
                'samples_after_undersampling': len(X_train_resampled),
                'positive_rate_after': np.mean(Y_train_resampled),
                'rmse': eval_results['rmse'],
                'bias': eval_results['bias'],
                'mae': eval_results['mae']
            })
            
            print(f"k={k} çµæœ:")
            print(f"- RMSE: {eval_results['rmse']:.4f}")
            print(f"- Bias: {eval_results['bias']:.4f}")
            print(f"- MAE: {eval_results['mae']:.4f}")
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒ
            rmse_improvement = (baseline_eval['rmse'] - eval_results['rmse']) / baseline_eval['rmse'] * 100
            bias_improvement = (abs(baseline_eval['bias']) - abs(eval_results['bias'])) / abs(baseline_eval['bias']) * 100
            
            print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®æ”¹å–„:")
            print(f"- RMSEæ”¹å–„: {rmse_improvement:+.2f}%")
            print(f"- Biasæ”¹å–„: {bias_improvement:+.2f}%")
            print()
            
        except Exception as e:
            print(f"k={k} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            print()
            continue
    
    # çµæœã¾ã¨ã‚
    print("=" * 70)
    print("å®Ÿé¨“çµæœã¾ã¨ã‚")
    print("=" * 70)
    
    # çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    print(f"{'Kå€¤':<10} {'ã‚µãƒ³ãƒ—ãƒ«æ•°':<10} {'æ­£ä¾‹ç‡':<10} {'RMSE':<10} {'Bias':<10} {'MAE':<10}")
    print("-" * 70)
    
    for result in results:
        k_str = str(result['k_value'])
        samples = result['samples_after_undersampling']
        pos_rate = result['positive_rate_after']
        rmse = result['rmse']
        bias = result['bias']
        mae = result['mae']
        
        print(f"{k_str:<10} {samples:<10} {pos_rate:<10.4f} {rmse:<10.4f} {bias:<10.4f} {mae:<10.4f}")
    
    # æœ€é©kå€¤ã®æ¨å¥¨
    print()
    print("=" * 70)
    print("æ¨å¥¨äº‹é …")
    print("=" * 70)
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³é™¤å¤–ã—ã¦RMSEãŒæœ€å°ã®kå€¤ã‚’è¦‹ã¤ã‘ã‚‹
    k_results = [r for r in results if r['k_value'] != 'Baseline']
    if k_results:
        best_rmse_result = min(k_results, key=lambda x: x['rmse'])
        best_bias_result = min(k_results, key=lambda x: abs(x['bias']))
        
        print(f"æœ€å°RMSE: k={best_rmse_result['k_value']} (RMSE: {best_rmse_result['rmse']:.4f})")
        print(f"æœ€å°Bias: k={best_bias_result['k_value']} (Bias: {best_bias_result['bias']:.4f})")
        
        # k=3ã®çµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        k3_result = next((r for r in k_results if r['k_value'] == 3.0), None)
        if k3_result:
            print()
            print(f"ğŸ“Š k=3ã®æ€§èƒ½:")
            print(f"- RMSE: {k3_result['rmse']:.4f}")
            print(f"- Bias: {k3_result['bias']:.4f}")
            print(f"- ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ç‡: {(1 - k3_result['samples_after_undersampling'] / len(X_train)) * 100:.1f}%")
            
            baseline_rmse = next(r['rmse'] for r in results if r['k_value'] == 'Baseline')
            improvement = (baseline_rmse - k3_result['rmse']) / baseline_rmse * 100
            print(f"- ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®RMSEæ”¹å–„: {improvement:+.2f}%")
    
    print("\nâœ… Kå€¤æ¤œè¨¼å®Ÿé¨“å®Œäº†!")
    return results

def quick_k3_test():
    """k=3ã§ã®ç°¡å˜ãªãƒ†ã‚¹ãƒˆ"""
    print("=" * 50)
    print("K=3 ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    # å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¿…é€Ÿãƒ†ã‚¹ãƒˆ
    X, T, Y, true_cate = create_imbalanced_dataset(n_samples=1000, positive_rate=0.03, random_seed=42)
    
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿:")
    print(f"- ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
    print(f"- æ­£ä¾‹ç‡: {np.mean(Y):.4f}")
    
    # k=3ã§ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    undersampler = UpliftUndersampler(k=3.0, random_state=42)
    X_resampled, T_resampled, Y_resampled = undersampler.fit_resample(X, T, Y)
    
    print(f"\nã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œ:")
    print(f"- ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_resampled)}")
    print(f"- æ­£ä¾‹ç‡: {np.mean(Y_resampled):.4f}")
    print(f"- ãƒ‡ãƒ¼ã‚¿ä¿æŒç‡: {len(X_resampled) / len(X) * 100:.1f}%")
    
    print("\nâœ… K=3ãƒ†ã‚¹ãƒˆå®Œäº†!")

if __name__ == "__main__":
    print("ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° Kå€¤æ¤œè¨¼ãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    print("=" * 70)
    
    # ã¾ãšã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    quick_k3_test()
    print("\n")
    
    # è©³ç´°ãªkå€¤æ¯”è¼ƒå®Ÿé¨“
    try:
        results = run_k_value_experiment(
            k_values=[2.0, 3.0, 4.0, 5.0],
            n_samples=2000,  # ã‚ˆã‚Šå°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã§é«˜é€ŸåŒ–
            positive_rate=0.04
        )
        
        print("\nğŸ‰ å…¨ã¦ã®å®Ÿé¨“ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
        
    except Exception as e:
        print(f"\nâŒ å®Ÿé¨“ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
